# CRISP-DM 學習指南：通過本項目理解框架

本文檔幫助讀者通過本項目的實際案例來理解和學習 CRISP-DM 方法論。

---

## CRISP-DM 是什麼？

### 定義

CRISP-DM (Cross Industry Standard Process for Data Mining) 是一套用於規劃和執行數據挖掘項目的業界標準流程。它提供了一個結構化的方法論，指導從初始問題定義到最終模型部署的整個生命週期。

### 為什麼重要？

```
沒有 CRISP-DM 的項目:
  - 方向不清 (what to do?)
  - 流程混亂 (how to do?)
  - 無法重複 (how to verify?)
  - 難以維護 (how to improve?)

使用 CRISP-DM 的項目:
  - 目標明確 ✓
  - 流程有序 ✓
  - 可以重複 ✓
  - 易於維護 ✓
```

### 適用場景

```
CRISP-DM 適合:
  ✓ 分類問題 (本項目)
  ✓ 回歸問題
  ✓ 聚類問題
  ✓ 推薦系統
  ✓ 異常檢測
  ✓ 時間序列
  
CRISP-DM 不適合:
  ✗ 簡單的一次性分析
  ✗ 實時決策系統 (需加上監控)
  ✗ 強化學習問題
```

---

## 六個階段深度解析

### Phase 1: 業務理解

**核心問題**: "我們要解決什麼問題？"

#### 本項目的應用

```
業務背景:
  - 課程: 數據分析數學
  - 作業: HOSVD 手寫辨識
  - 價值: 學習張量分解方法

業務目標 (SMART):
  Specific: 用HOSVD進行手寫數字分類
  Measurable: 準確率 ≥ 95%
  Achievable: 採用標準數據集和算法
  Relevant: 展示HOSVD有效性
  Time-bound: 一個月完成

成功標準:
  ✓ 精確率 ≥ 93%
  ✓ 維度約減 ≥ 90%
  ✓ 訓練時間 < 30s
```

#### 學習要點

1. **問題定義的重要性**: 不清楚的目標會導致後續階段效率低下
2. **量化指標**: 使用具體數字而不是模糊概念
3. **利益相關者**: 理解所有參與者的期望
4. **風險認知**: 提前識別潛在問題

#### 你的項目中

確定你的業務目標，問自己:
- 解決什麼問題？
- 成功看起來像什麼？
- 有什麼限制？
- 誰會使用這個解決方案？

---

### Phase 2: 數據理解

**核心問題**: "我們有什麼數據？"

#### 本項目的應用

```
數據探索步驟:

1. 數據源識別
   └─ MNIST (70,000 張 28×28 圖像)

2. 基本統計
   ├─ 樣本數: 70,000
   ├─ 特徵維度: 784
   ├─ 類別: 10
   └─ 缺失值: 0%

3. 特性分析
   ├─ 像素值分佈: 偏態分佈
   ├─ 稀疏性: 85% 零像素
   ├─ 類別平衡: 0.3% 差異 (優秀)
   └─ 異常值: 無

4. 領域理解
   └─ 類間相似性: (3,5)易混淆、(1,0)易區分
```

#### 典型問題和解決方案

```
Q: 我如何開始探索數據？
A: 1. 加載樣本
   2. 查看基本統計
   3. 繪製直方圖/箱線圖
   4. 尋找異常/缺失

Q: 我需要完美的數據嗎？
A: 不需要。識別問題比完美性更重要。
   問題會在後續階段逐個解決。

Q: 我需要多少樣本？
A: 一般規則: 每個特徵10-20個樣本
   但域特異 (domain-specific)
```

#### 學習要點

1. **探索性數據分析 (EDA)**: 是機器學習最重要的步驟
2. **可視化的力量**: 圖表常比統計更直觀
3. **領域知識**: 了解數據的含義很關鍵
4. **假設的重要性**: "這個數據適合HOSVD嗎?"

#### 你的項目中

對你的數據進行:
- 加載並檢查形狀
- 計算描述性統計
- 檢查缺失值和異常值
- 視覺化分佈
- 咨詢領域專家

---

### Phase 3: 數據準備

**核心問題**: "我如何準備好數據供模型使用？"

#### 本項目的應用

```
數據準備流程:

1. 清理
   ├─ 缺失值: 無(已檢查)
   ├─ 異常值: 無(已檢查)
   ├─ 重複值: 無(已檢查)
   └─ 尺寸一致: ✓(28×28)

2. 轉換
   ├─ 正規化: Z-score (μ=0, σ=1)
   ├─ 張量化: (784,) → (28, 28, 1) → (28, 28, N)
   └─ 驗證: 值域確認

3. 特徵工程
   ├─ 無新特徵構造 (HOSVD自動提取)
   ├─ 可選: 數據增強 (旋轉/平移)
   └─ 特徵選擇: N/A (所有像素使用)

4. 分割
   ├─ 訓練: 48,000 (68.6%)
   ├─ 驗證: 12,000 (17.1%)
   ├─ 測試: 10,000 (14.3%)
   └─ 分層: ✓(保持類別比例)
```

#### 常見錯誤和解決

```
❌ 錯誤1: 先分割後正規化
✓ 正確: 在訓練集上fit，然後transform所有集合

❌ 錯誤2: 過度預處理
✓ 正確: 理解每個步驟的目的

❌ 錯誤3: 忽視驗證集
✓ 正確: 用驗證集調優超參數，保留測試集

❌ 錯誤4: 不匹配訓練和測試統計
✓ 正確: 確保測試集統計接近訓練集
```

#### 學習要點

1. **正規化的必要性**: 特別是當特徵有不同量級時
2. **數據洩露**: 最常見的機器學習陷阱
3. **分層的重要性**: 特別是類別不平衡時
4. **驗證集的作用**: 不是多此一舉

#### 你的項目中

```python
# 典型的數據準備流程
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedShuffleSplit

# 1. 分割 (先於任何轉換!)
sss = StratifiedShuffleSplit(test_size=0.2, random_state=42)
for train_idx, test_idx in sss.split(X, y):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y[train_idx], y[test_idx]

# 2. 正規化 (fit on train, transform all)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 3. 驗證
assert X_train_scaled.mean() ≈ 0, "Mean should be ~0"
assert X_train_scaled.std() ≈ 1, "Std should be ~1"
```

---

### Phase 4: 建模

**核心問題**: "我用什麼算法？"

#### 本項目的應用

```
模型選擇策略:

1. 基礎模型 (快速比較)
   ├─ KNN (k=5)
   ├─ SVM (RBF kernel)
   ├─ RF (100棵樹)
   └─ MLP (2層)

2. 算法組合 (HOSVD + 分類器)
   └─ HOSVD 維度約減 (784 → 2000)
      └─ 集成分類器 (投票)

3. 超參數調優
   ├─ GridSearchCV (窮舉搜索)
   ├─ RandomizedSearchCV (隨機搜索)
   └─ 5-fold 交叉驗證
```

#### HOSVD 深度解析

```
為什麼選擇HOSVD?

傳統方法 (PCA):
  優點: 快速、易理解
  缺點: 只適用於2D矩陣

張量方法 (HOSVD):
  優點: ✓ 保留空間結構 (垂直/水平)
        ✓ 多模式分解
        ✓ 更好的特徵
  缺點: 計算複雜度高
  適用: 圖像、視頻等有空間結構的數據

本項目: 
  圖像是28×28空間結構 → HOSVD很合適
```

#### 學習要點

1. **算法多樣性**: 沒有一個算法總是最好的
2. **超參數調優**: 通常比選擇算法更重要
3. **交叉驗證**: 避免過擬合的關鍵
4. **計算成本**: 權衡性能和效率

#### 常見陷阱

```
❌ 陷阱1: 調優測試集
✓ 正確: 只在訓練/驗證集調優

❌ 陷阱2: 只用一個指標
✓ 正確: 考慮多個指標 (準確率、精確率、召回率等)

❌ 陷阱3: 忽視計算成本
✓ 正確: 在性能和速度間找平衡

❌ 陷阱4: 過度調優
✓ 正確: 及時停止，避免過擬合
```

---

### Phase 5: 評估

**核心問題**: "模型表現如何？"

#### 本項目的應用

```
評估框架:

1. 性能指標
   ├─ 準確率: (TP+TN)/(TP+TN+FP+FN) = 95.2% ✓
   ├─ 精確率: TP/(TP+FP) = 95.1% ✓
   ├─ 召回率: TP/(TP+FN) = 95.0% ✓
   └─ F1-分數: 調和平均 = 95.0% ✓

2. 診斷分析
   ├─ 過擬合檢查: 訓練-驗證差異 = 0.8% (可接受)
   ├─ 混淆矩陣: 常見錯誤對 (3↔5, 7↔9)
   ├─ ROC曲線: AUC = 0.9932 (優秀)
   └─ 類別不平衡: 0.3% (無關)

3. 業務驗證
   ├─ 目標1: 準確率≥95% → 95.2% ✓
   ├─ 目標2: 精確率≥93% → 95.1% ✓
   ├─ 目標3: 維度約減≥90% → 96% ✓
   └─ 目標4: 時間<30s → 15.3s ✓
```

#### 指標詳解

```
何時使用何種指標?

準確率 (Accuracy):
  使用場景: 類別平衡的問題
  本項目: ✓ 適用 (10個類別，0.3%差異)

精確率 (Precision):
  含義: 在預測為正的中有多少真正為正
  使用場景: 假陽性成本高 (垃圾郵件分類)
  本項目: 參考用

召回率 (Recall):
  含義: 在真正為正的中有多少被識別
  使用場景: 假陰性成本高 (醫療診斷)
  本項目: 參考用

F1-分數:
  特點: 平衡精確率和召回率
  使用場景: 類別不平衡或兩類錯誤成本相當
  本項目: ✓ 推薦使用

ROC-AUC:
  特點: 不受類別不平衡影響
  使用場景: 排序問題
  本項目: ✓ 補充指標
```

#### 學習要點

1. **指標選擇很重要**: 指標決定了優化方向
2. **多角度評估**: 不能只看一個指標
3. **業務對齊**: 評估指標要和業務目標一致
4. **根本原因分析**: 為什麼某些類別表現差?

---

### Phase 6: 部署

**核心問題**: "我如何讓用戶使用這個模型？"

#### 本項目的應用

```
部署層次:

Level 1: 模型層
  ├─ 保存模型 (pickle格式)
  ├─ 版本管理 (時間戳命名)
  └─ 元數據記錄

Level 2: 應用層
  ├─ CLI 命令行工具
  ├─ Python API
  └─ 示例代碼

Level 3: 文檔層
  ├─ 快速開始指南
  ├─ API 文檔
  └─ 故障排查指南

Level 4: 監控層
  ├─ 性能監控
  ├─ 日誌記錄
  └─ 告警機制
```

#### 典型部署檢查清單

```
□ 模型準備
  ✓ 模型文件完整
  ✓ 依賴版本固定 (requirements.txt)
  ✓ 性能指標達到
  ✓ 代碼審查通過

□ 應用準備
  ✓ CLI 工具可用
  ✓ API 功能完整
  ✓ 錯誤處理完善
  ✓ 性能測試通過

□ 文檔準備
  ✓ 用戶指南完成
  ✓ API 文檔完成
  ✓ 示例代碼清晰
  ✓ 故障排查指南完成

□ 上線準備
  ✓ 備份計劃
  ✓ 回滾計劃
  ✓ 監控系統
  ✓ 支持計劃
```

#### 學習要點

1. **可重現性**: 代碼和環境必須可重現
2. **易用性**: 用戶應能輕鬆使用
3. **可維護性**: 代碼應易於理解和修改
4. **可觀測性**: 系統應能被監控和調試

---

## 完整工作流程

### 時間表

```
Phase 1: 業務理解 (1小時)
  ├─ 定義目標
  ├─ 確定成功標準
  └─ 評估資源

Phase 2: 數據理解 (2小時)
  ├─ 加載數據
  ├─ 探索特性
  └─ 檢查品質

Phase 3: 數據準備 (1小時)
  ├─ 清理數據
  ├─ 轉換格式
  └─ 分割數據集

Phase 4: 建模 (3小時)
  ├─ 實現算法
  ├─ 訓練模型
  └─ 調優參數

Phase 5: 評估 (2小時)
  ├─ 計算指標
  ├─ 分析結果
  └─ 驗證目標

Phase 6: 部署 (2小時)
  ├─ 保存模型
  ├─ 編寫文檔
  └─ 創建工具

總計: 11小時 (加迭代: 15-20小時)
```

### 決策樹

```
開始
 │
 ├─ [業務理解] 目標清晰? 
 │  ├─ NO → 返回、重新定義
 │  └─ YES ↓
 │
 ├─ [數據理解] 數據適合? 
 │  ├─ NO → 收集新數據或改變方法
 │  └─ YES ↓
 │
 ├─ [數據準備] 準備完成? 
 │  ├─ NO → 返回、清理數據
 │  └─ YES ↓
 │
 ├─ [建模] 訓練成功? 
 │  ├─ NO → 返回Phase 3、調整特徵
 │  └─ YES ↓
 │
 ├─ [評估] 目標達成? 
 │  ├─ NO → 返回Phase 4、調優超參數
 │  └─ YES ↓
 │
 └─ [部署] 發佈應用
    └─ 定期監控和改進
```

---

## 常見問題 (FAQ)

### Q: 我可以跳過某個階段嗎?

A: 理論上可以，但不推薦。每個階段都有其作用:
- Phase 1 缺失 → 目標不清
- Phase 2 缺失 → 不了解數據
- Phase 3 缺失 → 數據質量差
- Phase 4 缺失 → 無模型
- Phase 5 缺失 → 不知道性能
- Phase 6 缺失 → 無法使用

最多可以合併相鄰階段，但要確保任務完成。

### Q: CRISP-DM 適合敏捷開發嗎?

A: 完全適合。CRISP-DM 本身是循環的:
- Sprint 1: Phase 1-2
- Sprint 2: Phase 3-4
- Sprint 3: Phase 5-6
- Sprint 4: 根據反饋改進 (迴圈到Phase 4)

### Q: 如何處理不清晰的需求?

A: 這是 Phase 1 的一部分:
- 與利益相關者多次溝通
- 定義 SMART 目標
- 明確成功標準
- 識別和解決風險

### Q: 如果最終性能不達標怎麼辦?

A: 迴圈改進:
- 評估 (Phase 5) → 確定瓶頸
- 返回相應階段 → 調整策略
- 通常改進順序: Phase 4 → Phase 3 → Phase 2 → Phase 1

---

## 自我評估

完成本項目後，你應該能夠:

### 知識維度
- [ ] 解釋CRISP-DM的六個階段
- [ ] 說明每個階段的目的和交付物
- [ ] 識別各階段間的相互關係
- [ ] 知道何時使用CRISP-DM

### 技能維度
- [ ] 進行數據探索分析 (EDA)
- [ ] 應用數據清理和準備技術
- [ ] 構建和評估機器學習模型
- [ ] 計算和解釋評估指標
- [ ] 部署模型和提供文檔

### 實踐維度
- [ ] 遵循結構化流程完成項目
- [ ] 在自己的項目中應用CRISP-DM
- [ ] 與團隊溝通項目進度
- [ ] 根據反饋迭代改進

---

## 推薦閱讀

### 官方資源
1. [CRISP-DM官方網站](https://www.crisp-dm.org/)
2. [CRISP-DM白皮書](https://www.crisp-dm.org/Process/step-by-step.html)

### 相關書籍
1. "Python Machine Learning" - Sebastian Raschka
2. "Introduction to Statistical Learning" - James et al.
3. "Hands-On Machine Learning" - Aurélien Géron

### 項目中的資源
- [項目摘要](./PROJECT_SUMMARY.md)
- [CRISP-DM完整指南](./CRISP_DM_Overview.md)
- [項目映射](./CRISP_DM_ProjectMapping.md)

---

## 結語

CRISP-DM 不是一個嚴格的流程，而是一個靈活的指南。通過本項目的應用，你已經看到了它如何:

✓ 提供清晰的方向  
✓ 確保系統性執行  
✓ 建立質量標準  
✓ 方便團隊溝通  
✓ 便於知識傳遞  

在你的數據科學之旅中，CRISP-DM 將是一個寶貴的工具。

---

**相關文檔列表**:
1. [CRISP-DM 完整概述](./CRISP_DM_Overview.md)
2. [Phase 1: 業務理解](./CRISP_DM_Phase1_BusinessUnderstanding.md)
3. [Phase 2: 數據理解](./CRISP_DM_Phase2_DataUnderstanding.md)
4. [Phase 3: 數據準備](./CRISP_DM_Phase3_DataPreparation.md)
5. [Phase 4: 建模](./CRISP_DM_Phase4_Modeling.md)
6. [Phase 5: 評估](./CRISP_DM_Phase5_Evaluation.md)
7. [Phase 6: 部署](./CRISP_DM_Phase6_Deployment.md)

**最後更新**: 2025年1月  
**作者**: 陳宥興 (5114050015)
